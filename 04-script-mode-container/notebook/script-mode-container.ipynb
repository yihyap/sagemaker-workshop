{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Script-mode Custom Training Container</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to build and use a custom Docker container for training with Amazon SageMaker that leverages on the <strong>Script Mode</strong> execution that is implemented by the sagemaker-containers library. Reference documentation is available at https://github.com/aws/sagemaker-containers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by defining some variables like the current execution role, the ECR repository that we are going to use for pushing the custom Docker container and a default Amazon S3 bucket to be used by Amazon SageMaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "342474125894\n",
      "ap-southeast-1\n",
      "arn:aws:iam::342474125894:role/service-role/AmazonSageMaker-ExecutionRole-20190405T234154\n",
      "sagemaker-ap-southeast-1-342474125894\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "ecr_namespace = 'sagemaker-training-containers/'\n",
    "prefix = 'script-mode-container'\n",
    "\n",
    "ecr_repository_name = ecr_namespace + prefix\n",
    "role = \"arn:aws:iam::342474125894:role/service-role/AmazonSageMaker-ExecutionRole-20190405T234154\"\n",
    "account_id = role.split(':')[4]\n",
    "region = boto3.Session().region_name\n",
    "sagemaker_session = sagemaker.session.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "print(account_id)\n",
    "print(region)\n",
    "print(role)\n",
    "print(bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the Dockerfile which defines the statements for building our script-mode custom training container:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m# Part of the implementation of this container is based on the Amazon SageMaker Apache MXNet container.\u001b[39;49;00m\n",
      "\u001b[37m# https://github.com/aws/sagemaker-mxnet-container\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mFROM\u001b[39;49;00m \u001b[33mubuntu:16.04\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mLABEL\u001b[39;49;00m \u001b[31mmaintainer\u001b[39;49;00m=\u001b[33m\"Giuseppe A. Porcelli\"\u001b[39;49;00m\n",
      "\n",
      "\u001b[37m# Defining some variables used at build time to install Python3\u001b[39;49;00m\n",
      "\u001b[34mARG\u001b[39;49;00m \u001b[31mPYTHON\u001b[39;49;00m=python3\n",
      "\u001b[34mARG\u001b[39;49;00m \u001b[31mPYTHON_PIP\u001b[39;49;00m=python3-pip\n",
      "\u001b[34mARG\u001b[39;49;00m \u001b[31mPIP\u001b[39;49;00m=pip3\n",
      "\u001b[34mARG\u001b[39;49;00m \u001b[31mPYTHON_VERSION\u001b[39;49;00m=\u001b[34m3\u001b[39;49;00m.6.6\n",
      "\n",
      "\u001b[37m# Install some handful libraries like curl, wget, git, build-essential, zlib\u001b[39;49;00m\n",
      "\u001b[34mRUN\u001b[39;49;00m apt-get update && apt-get install -y --no-install-recommends software-properties-common && \u001b[33m\\\u001b[39;49;00m\n",
      "    add-apt-repository ppa:deadsnakes/ppa -y && \u001b[33m\\\u001b[39;49;00m\n",
      "    apt-get update && apt-get install -y --no-install-recommends \u001b[33m\\\u001b[39;49;00m\n",
      "        build-essential \u001b[33m\\\u001b[39;49;00m\n",
      "        ca-certificates \u001b[33m\\\u001b[39;49;00m\n",
      "        curl \u001b[33m\\\u001b[39;49;00m\n",
      "        wget \u001b[33m\\\u001b[39;49;00m\n",
      "        git \u001b[33m\\\u001b[39;49;00m\n",
      "        libopencv-dev \u001b[33m\\\u001b[39;49;00m\n",
      "        openssh-client \u001b[33m\\\u001b[39;49;00m\n",
      "        openssh-server \u001b[33m\\\u001b[39;49;00m\n",
      "        vim \u001b[33m\\\u001b[39;49;00m\n",
      "        zlib1g-dev && \u001b[33m\\\u001b[39;49;00m\n",
      "    rm -rf /var/lib/apt/lists/*\n",
      "\n",
      "\u001b[37m# Installing Python3\u001b[39;49;00m\n",
      "\u001b[34mRUN\u001b[39;49;00m wget https://www.python.org/ftp/python/\u001b[31m$PYTHON_VERSION\u001b[39;49;00m/Python-\u001b[31m$PYTHON_VERSION\u001b[39;49;00m.tgz && \u001b[33m\\\u001b[39;49;00m\n",
      "        tar -xvf Python-\u001b[31m$PYTHON_VERSION\u001b[39;49;00m.tgz && \u001b[36mcd\u001b[39;49;00m Python-\u001b[31m$PYTHON_VERSION\u001b[39;49;00m && \u001b[33m\\\u001b[39;49;00m\n",
      "        ./configure && make && make install && \u001b[33m\\\u001b[39;49;00m\n",
      "        apt-get update && apt-get install -y --no-install-recommends libreadline-gplv2-dev libncursesw5-dev libssl-dev libsqlite3-dev tk-dev libgdbm-dev libc6-dev libbz2-dev && \u001b[33m\\\u001b[39;49;00m\n",
      "        make && make install && rm -rf ../Python-\u001b[31m$PYTHON_VERSION\u001b[39;49;00m* && \u001b[33m\\\u001b[39;49;00m\n",
      "        ln -s /usr/local/bin/pip3 /usr/bin/pip\n",
      "\n",
      "\u001b[37m# Upgrading pip and creating symbolic link for python3\u001b[39;49;00m\n",
      "\u001b[34mRUN\u001b[39;49;00m \u001b[33m${\u001b[39;49;00m\u001b[31mPIP\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m --no-cache-dir install --upgrade pip\n",
      "\u001b[34mRUN\u001b[39;49;00m ln -s \u001b[34m$(\u001b[39;49;00mwhich \u001b[33m${\u001b[39;49;00m\u001b[31mPYTHON\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[34m)\u001b[39;49;00m /usr/local/bin/python\n",
      "\n",
      "\u001b[34mWORKDIR\u001b[39;49;00m\u001b[33m /\u001b[39;49;00m\n",
      "\n",
      "\u001b[37m# Installing numpy, pandas, scikit-learn, scipy\u001b[39;49;00m\n",
      "\u001b[34mRUN\u001b[39;49;00m \u001b[33m${\u001b[39;49;00m\u001b[31mPIP\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m install --no-cache --upgrade \u001b[33m\\\u001b[39;49;00m\n",
      "        \u001b[31mnumpy\u001b[39;49;00m==\u001b[34m1\u001b[39;49;00m.14.5 \u001b[33m\\\u001b[39;49;00m\n",
      "        \u001b[31mpandas\u001b[39;49;00m==\u001b[34m0\u001b[39;49;00m.24.1 \u001b[33m\\\u001b[39;49;00m\n",
      "        scikit-learn==\u001b[34m0\u001b[39;49;00m.20.3 \u001b[33m\\\u001b[39;49;00m\n",
      "        \u001b[31mrequests\u001b[39;49;00m==\u001b[34m2\u001b[39;49;00m.21.0 \u001b[33m\\\u001b[39;49;00m\n",
      "        \u001b[31mscipy\u001b[39;49;00m==\u001b[34m1\u001b[39;49;00m.2.1\n",
      "\n",
      "\u001b[37m# Setting some environment variables.\u001b[39;49;00m\n",
      "\u001b[34mENV\u001b[39;49;00m \u001b[31mPYTHONDONTWRITEBYTECODE\u001b[39;49;00m=\u001b[34m1\u001b[39;49;00m \u001b[33m\\\u001b[39;49;00m\n",
      "    \u001b[31mPYTHONUNBUFFERED\u001b[39;49;00m=\u001b[34m1\u001b[39;49;00m \u001b[33m\\\u001b[39;49;00m\n",
      "    \u001b[31mLD_LIBRARY_PATH\u001b[39;49;00m=\u001b[33m\"\u001b[39;49;00m\u001b[33m${\u001b[39;49;00m\u001b[31mLD_LIBRARY_PATH\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m:/usr/local/lib\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[33m\\\u001b[39;49;00m\n",
      "    \u001b[31mPYTHONIOENCODING\u001b[39;49;00m=UTF-8 \u001b[33m\\\u001b[39;49;00m\n",
      "    \u001b[31mLANG\u001b[39;49;00m=C.UTF-8 \u001b[33m\\\u001b[39;49;00m\n",
      "    \u001b[31mLC_ALL\u001b[39;49;00m=C.UTF-8\n",
      "\n",
      "\u001b[34mRUN\u001b[39;49;00m \u001b[33m${\u001b[39;49;00m\u001b[31mPIP\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m install --no-cache --upgrade \u001b[33m\\\u001b[39;49;00m\n",
      "    sagemaker-containers\n",
      "\n",
      "\u001b[37m# Copies code under /opt/ml/code where sagemaker-containers expects to find the script to run\u001b[39;49;00m\n",
      "\u001b[34mCOPY\u001b[39;49;00m code/* /opt/ml/code/\n",
      "\n",
      "\u001b[37m# Defines train.py as script entry point\u001b[39;49;00m\n",
      "\u001b[34mENV\u001b[39;49;00m SAGEMAKER_PROGRAM train.py\n"
     ]
    }
   ],
   "source": [
    "! pygmentize ../docker/Dockerfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At high-level the Dockerfile specifies the following operations for building this container:\n",
    "<ul>\n",
    "    <li>Start from Ubuntu 16.04</li>\n",
    "    <li>Define some variables to be used at build time to install Python 3</li>\n",
    "    <li>Some handful libraries are installed with apt-get</li>\n",
    "    <li>We then install Python 3 and create a symbolic link</li>\n",
    "    <li>We install some Python libraries like numpy, pandas, ScikitLearn, etc.</li>\n",
    "    <li>We set e few environment variables, including PYTHONUNBUFFERED which is used to avoid buffering Python standard output (useful for logging)</li>\n",
    "    <li>We install the <strong>sagemaker-containers</strong> library</li>\n",
    "    <li>Finally, we copy all contents in <strong>code/</strong> (which is where our training code is) under <strong>/opt/ml/code/</strong> which is the path where sagemaker-containers expect to find training code</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Build and push the container</h3>\n",
    "We are now ready to build this container and push it to Amazon ECR. This task is executed using a shell script stored in the ../script/ folder. Let's take a look at this script and then execute it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mACCOUNT_ID\u001b[39;49;00m=\u001b[31m$1\u001b[39;49;00m\n",
      "\u001b[31mREGION\u001b[39;49;00m=\u001b[31m$2\u001b[39;49;00m\n",
      "\u001b[31mREPO_NAME\u001b[39;49;00m=\u001b[31m$3\u001b[39;49;00m\n",
      "\n",
      "docker build -f ../docker/Dockerfile -t \u001b[31m$REPO_NAME\u001b[39;49;00m ../docker\n",
      "\n",
      "docker tag \u001b[31m$REPO_NAME\u001b[39;49;00m \u001b[31m$ACCOUNT_ID\u001b[39;49;00m.dkr.ecr.\u001b[31m$REGION\u001b[39;49;00m.amazonaws.com/\u001b[31m$REPO_NAME\u001b[39;49;00m:latest\n",
      "\n",
      "\u001b[34m$(\u001b[39;49;00maws ecr get-login --no-include-email --registry-ids \u001b[31m$ACCOUNT_ID\u001b[39;49;00m\u001b[34m)\u001b[39;49;00m\n",
      "\n",
      "aws ecr describe-repositories --repository-names \u001b[31m$REPO_NAME\u001b[39;49;00m || aws ecr create-repository --repository-name \u001b[31m$REPO_NAME\u001b[39;49;00m\n",
      "\n",
      "docker push \u001b[31m$ACCOUNT_ID\u001b[39;49;00m.dkr.ecr.\u001b[31m$REGION\u001b[39;49;00m.amazonaws.com/\u001b[31m$REPO_NAME\u001b[39;49;00m:latest\n"
     ]
    }
   ],
   "source": [
    "! pygmentize ../scripts/build_and_push.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>--------------------------------------------------------------------------------------------------------------------</h3>\n",
    "\n",
    "The script builds the Docker container, then creates the repository if it does not exist, and finally pushes the container to the ECR repository. The build task requires a few minutes to be executed the first time, then Docker caches build outputs to be reused for the subsequent build operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  8.192kB\n",
      "Step 1/16 : FROM ubuntu:16.04\n",
      " ---> 13c9f1285025\n",
      "Step 2/16 : LABEL maintainer=\"Giuseppe A. Porcelli\"\n",
      " ---> Using cache\n",
      " ---> 6bbf3d07c68d\n",
      "Step 3/16 : ARG PYTHON=python3\n",
      " ---> Using cache\n",
      " ---> 8e254b9ef0a0\n",
      "Step 4/16 : ARG PYTHON_PIP=python3-pip\n",
      " ---> Using cache\n",
      " ---> 84c928b11bb3\n",
      "Step 5/16 : ARG PIP=pip3\n",
      " ---> Using cache\n",
      " ---> 65e780b1f9d7\n",
      "Step 6/16 : ARG PYTHON_VERSION=3.6.6\n",
      " ---> Using cache\n",
      " ---> 03bab72f170e\n",
      "Step 7/16 : RUN apt-get update && apt-get install -y --no-install-recommends software-properties-common &&     add-apt-repository ppa:deadsnakes/ppa -y &&     apt-get update && apt-get install -y --no-install-recommends         build-essential         ca-certificates         curl         wget         git         libopencv-dev         openssh-client         openssh-server         vim         zlib1g-dev &&     rm -rf /var/lib/apt/lists/*\n",
      " ---> Using cache\n",
      " ---> 0b3f66ca4c73\n",
      "Step 8/16 : RUN wget https://www.python.org/ftp/python/$PYTHON_VERSION/Python-$PYTHON_VERSION.tgz &&         tar -xvf Python-$PYTHON_VERSION.tgz && cd Python-$PYTHON_VERSION &&         ./configure && make && make install &&         apt-get update && apt-get install -y --no-install-recommends libreadline-gplv2-dev libncursesw5-dev libssl-dev libsqlite3-dev tk-dev libgdbm-dev libc6-dev libbz2-dev &&         make && make install && rm -rf ../Python-$PYTHON_VERSION* &&         ln -s /usr/local/bin/pip3 /usr/bin/pip\n",
      " ---> Using cache\n",
      " ---> da24d9684dbd\n",
      "Step 9/16 : RUN ${PIP} --no-cache-dir install --upgrade pip\n",
      " ---> Using cache\n",
      " ---> a7e0f5c77b12\n",
      "Step 10/16 : RUN ln -s $(which ${PYTHON}) /usr/local/bin/python\n",
      " ---> Using cache\n",
      " ---> 9970f3a50688\n",
      "Step 11/16 : WORKDIR /\n",
      " ---> Using cache\n",
      " ---> 7185a26a84ec\n",
      "Step 12/16 : RUN ${PIP} install --no-cache --upgrade         numpy==1.14.5         pandas==0.24.1         scikit-learn==0.20.3         requests==2.21.0         scipy==1.2.1\n",
      " ---> Running in 75b099fc2d3a\n",
      "Collecting numpy==1.14.5\n",
      "  Downloading numpy-1.14.5-cp36-cp36m-manylinux1_x86_64.whl (12.2 MB)\n",
      "Collecting pandas==0.24.1\n",
      "  Downloading pandas-0.24.1-cp36-cp36m-manylinux1_x86_64.whl (10.1 MB)\n",
      "Collecting scikit-learn==0.20.3\n",
      "  Downloading scikit_learn-0.20.3-cp36-cp36m-manylinux1_x86_64.whl (5.4 MB)\n"
     ]
    }
   ],
   "source": [
    "! ../scripts/build_and_push.sh $account_id $region $ecr_repository_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Training with Amazon SageMaker</h3>\n",
    "\n",
    "Once we have correctly pushed our container to Amazon ECR, we are ready to start training with Amazon SageMaker, which requires the ECR path to the Docker container used for training as parameter for starting a training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "container_image_uri = '{0}.dkr.ecr.{1}.amazonaws.com/{2}:latest'.format(account_id, region, ecr_repository_name)\n",
    "print(container_image_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the purpose of this example is explaining how to build custom script-mode containers, we are not going to train a real model. The script that will be executed does not define a specific training logic; it just outputs the configurations injected by SageMaker and implements a dummy training loop. Training data is also dummy. Let's analyze the script first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pygmentize ../docker/code/train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can realize that the training code has been implemented as a standard Python script, that will be invoked by the sagemaker-containers library passing hyperparameters as arguments. This way of invoking training script is indeed called <strong>Script Mode</strong> for Amazon SageMaker containers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we upload some dummy data to Amazon S3, in order to define our S3-based training channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! echo \"val1, val2, val3\" > dummy.csv\n",
    "print(sagemaker_session.upload_data('dummy.csv', bucket, prefix + '/train'))\n",
    "print(sagemaker_session.upload_data('dummy.csv', bucket, prefix + '/val'))\n",
    "! rm dummy.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can execute the training job by calling the fit() method of the generic Estimator object defined in the Amazon SageMaker Python SDK (https://github.com/aws/sagemaker-python-sdk/blob/master/src/sagemaker/estimator.py). This corresponds to calling the CreateTrainingJob() API (https://docs.aws.amazon.com/sagemaker/latest/dg/API_CreateTrainingJob.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import json\n",
    "\n",
    "# JSON encode hyperparameters to avoid showing some info messages raised by the sagemaker-containers library.\n",
    "def json_encode_hyperparameters(hyperparameters):\n",
    "    return {str(k): json.dumps(v) for (k, v) in hyperparameters.items()}\n",
    "\n",
    "hyperparameters = json_encode_hyperparameters({\n",
    "    \"hp1\": \"value1\",\n",
    "    \"hp2\": 300,\n",
    "    \"hp3\": 0.001})\n",
    "\n",
    "est = sagemaker.estimator.Estimator(container_image_uri,\n",
    "                                    role, \n",
    "                                    train_instance_count=1, \n",
    "                                    train_instance_type='local', # we use local mode\n",
    "                                    #train_instance_type='ml.m5.xlarge',\n",
    "                                    base_job_name=prefix,\n",
    "                                    hyperparameters=hyperparameters)\n",
    "\n",
    "train_config = sagemaker.session.s3_input('s3://{0}/{1}/train/'.format(bucket, prefix), content_type='text/csv')\n",
    "val_config = sagemaker.session.s3_input('s3://{0}/{1}/val/'.format(bucket, prefix), content_type='text/csv')\n",
    "\n",
    "est.fit({'train': train_config, 'validation': val_config })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smv2",
   "language": "python",
   "name": "smv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
